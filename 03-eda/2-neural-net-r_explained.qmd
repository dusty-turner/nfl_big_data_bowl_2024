---
title: "Neural-net"
author: "Dusty Turner"
format: html
engines:
  R: true
  python: true
cache: true
warning: false
message: false
echo: false
---

## Neural Network Explaination

The purpose of this file is to highlight the intricacies of the data structure for this LSTM Neural Network.

I present a summary of the data below.  I'm only showing about 1/9 of the data as I cannot work with it all on my office computer.

```{r}
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
library(data.table)
library(gganimate)
library(arrow)
source(here::here("03-eda","0-source-functions.R"))
if(digest::sha1(read_lines(here::here("03-eda", "1-data-cleaning.R"))) != read_lines(here::here("02-clean-data", "cleaninghash.txt"))){
  source(here::here("03-eda", "1-data-cleaning.R"))
} else {
  defensive_model_building_data <- read_parquet(here::here("02-clean-data", "defensive_model_building_data.parquet"))
  week_1 <- read_parquet(here::here("02-clean-data", "week_1.parquet"))
}

if (Sys.info()["user"] == "dusty_turner1") { ## looks for cheese grater
  mod <- read_rds(here::here("04-models", "model_data.rds"))
  x_train <- mod$x_train
  y_train <- mod$y_train
  max_length <- mod$max_length
  num_features <- dim(x_train)[3]
  x_test <- mod$x_test
  y_test <- mod$y_test
  time_steps <- mod$time_steps
  num_samples <- mod$num_samples
  tracking_test <- mod$tracking_test
  test_data <- mod$test_data
}

```



```{r}
deff <-
defensive_model_building_data %>% 
  # filter(is.na(pass_result)) |>
  # filter(frame_id >= 5) |> 
  filter(frames_from_tackle <=0) |> 

  # filter(frames_from_tackle >=-5) %>% 

  ## end finds frames from tackle
  mutate(position = as.character(position)) %>%
  mutate(position = replace_na(position, "unknown")) %>%
  mutate(position = factor(position)) |> 
  select(c(x,y,distance_to_ball, distance_to_ball_next, x_going, y_going, s, a, o, dir, x_ball, y_ball, x_ball_next, y_ball_next, s_ball, o_ball, dir_ball, angle_to_ball,
           position, offense_formation, quarter, down, rank, 
           alignment_cluster, play_type,
           defenders_in_the_box, ball_in_fan3, ball_in_fan2, ball_in_fan1, pass_probability, yards_to_go, x_from_los, height, weight, tackle, frames_from_tackle, game_id, play_id, nfl_id, frame_id, display_name, game_idplay_id)) 

library(mltools)
library(data.table)

should_be_factors <- c("ball_in_fan3", "ball_in_fan2", "ball_in_fan1", "position", "offense_formation", "quarter", "down", "rank", "defenders_in_the_box","alignment_cluster", "play_type")

continuous_factors <- c("x", "y", "x_ball", "y_ball", "s", "a", "o", "distance_to_ball", "x_going", "y_going", "dir", "x_ball_next", "y_ball_next", "s_ball", "o_ball", "dir_ball", "angle_to_ball", "pass_probability",  "yards_to_go", "x_from_los", "height", "weight")

discrete_factors <- c("quarter", "position", "offense_formation", "down", "rank", "defenders_in_the_box", 
                      "ball_in_fan3", "ball_in_fan2", "ball_in_fan1",
                      "alignment_cluster", "play_type")

non_centered_newdata <-
  deff |> 
  mutate(across(.cols = all_of(should_be_factors), ~as.factor(.))) |> 
  mutate(tackle = as.numeric(as.character(tackle))) |> 
  mutate(across(.cols = all_of(should_be_factors), .fns = ~if_else(is.na(.), "unknown", .))) |> 
  mutate(across(.cols = all_of(should_be_factors), ~as.factor(.))) |> 
  as.data.table() |> one_hot() |> 
  as_tibble() |> 
  mutate(across(.cols = where(is.character), .fns = ~as.factor(.))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.nan(.), NA, .))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.infinite(.), NA, .))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.na(.), mean(., na.rm = T), .))) |> 
  mutate(game_id = as.numeric(as.character(game_id))) |> 
  mutate(play_id = as.numeric(as.character(play_id))) |> 
  group_by(game_id, play_id, display_name, frame_id) |> ## because one play had two of these per player/frame for some reason
  mutate(x_from_los = mean(x_from_los)) |> 
  ungroup() |> 
  distinct(.keep_all = TRUE) |> 
  select(game_id,play_id, display_name, frame_id, all_of(continuous_factors), all_of(contains(discrete_factors)), tackle) |> 
  arrange(game_id, play_id, frame_id, display_name) 
  # select(game_id,play_id, display_name, frame_id, x, y, x_ball, y_ball, s, a, o, distance_to_ball, x_going, y_going, dir, x_ball_next, y_ball_next, s_ball, o_ball, dir_ball, angle_to_ball, pass_probability, tackle) |> 

newdata <- 
  non_centered_newdata |> 
  mutate(across(.cols = all_of(continuous_factors),  .fns = ~ (. - mean(.)) / sd(.))) 
```

The factors considered are below.

```{r}
select(non_centered_newdata, -display_name, -game_id, -play_id, -frame_id) |> skimr::skim()
```

## Keras / Tensorflow Requirements

Keras/Tensorflow require an LSTM to be in a unique shape.  

- Each row must be a time step.
- Each play must be in its own unique matrix.

This differs from how we typically conceptualize this data where each row is a player per time step.  

The implications is that we must shape the data to have 11 'y's where each column is a 0/1 if that player makes a tackle.  We must then widen the data also so that each factor, x coordinate for example, has 11 columns, one for each player.

Also, every matrix must be the same length.  This means that each play must be the same number of time steps.  We know this isn't true but we must pad all plays with '0' to be the length of the longest play.  This gets handled in our model specification. 

### Shape up Data

```{r}

# Function to extract play data for a given game and play id
get_play_data <- function(game_id_arg = 2022091112, play_id_arg = 86, df = newdata, 
                          num_features_per_player_arg = num_features_per_player) {
    # Select and arrange relevant data
    play_data <- df %>%
        filter(game_id == game_id_arg, play_id == play_id_arg) %>%
        arrange(frame_id, display_name)

    # Determine the number of unique frames and players
    num_frames <- length(unique(play_data$frame_id))
    num_players <- length(unique(play_data$display_name))

    # Initialize a matrix to store play data
    play_matrix <- matrix(nrow = num_frames, ncol = num_players * num_features_per_player)
dim(play_matrix)
    # Populate the matrix with data for each frame
    for (i in seq_len(num_frames)) {
        frame_data <- play_data %>%
            filter(frame_id == unique(play_data$frame_id)[i]) %>%
            select(all_of(continuous_factors), contains(discrete_factors))
            # select(x, y, x_ball, y_ball, s, a, o, distance_to_ball)
        play_matrix[i, ] <- as.numeric(t(frame_data))
    }
    play_matrix
}

num_features_per_player <- newdata |> select(-c(game_id, play_id, display_name, frame_id, tackle)) |> ncol()

# Extract unique game and play combinations from the dataset
example_play <- distinct(newdata, game_id, play_id) 

# Generate a list of matrices for each play

x_list <- x_list_maker()

# Determine the maximum sequence length and pad all sequences
max_length <- max(sapply(x_list, nrow))

pad_time_series <- function(x, max_length) {
    n_pad <- max_length - nrow(x)
    pad_matrix <- matrix(0, nrow = n_pad, ncol = ncol(x))
    rbind(x, pad_matrix)
}

x_padded <- lapply(x_list, pad_time_series, max_length = max_length)

# Function to create target matrices for each play
create_target_matrix <- function(game_id_arg, play_id_arg, df, padded_length) {
    # Filter and arrange data, then transform to wide format
    target_matrix <- df %>%
        filter(game_id == game_id_arg, play_id == play_id_arg) %>%
        arrange(frame_id, display_name) %>%
        select(display_name, tackle) %>%
        distinct() %>%
        pivot_wider(names_from = display_name, values_from = tackle) %>%
        mutate(n_rows = padded_length) %>%
        uncount(n_rows) %>%
        as.matrix()

    # Set column names for clarity
    colnames(target_matrix) <- paste0("Player ", 1:11)
    target_matrix
}

# Generate target matrices for each play

y_padded <- y_list_maker()

# Function to create a tracking array indicating the presence of data per player
create_tracking_array <- function(x, max_length, num_players) {
    tracking_array <- array(0, dim = c(max_length, num_players))
    if (nrow(x) > 0) {
        tracking_array[1:nrow(x), ] <- 1
    }
    tracking_array
}

# Generate tracking arrays for each play
tracking_list <- lapply(x_list, create_tracking_array, max_length = max_length, num_players = 11)

# Reshape x_padded into a 3D array
num_samples <- length(x_padded)
time_steps <- max_length  # Assuming max_length is already defined
num_features <- ncol(x_padded[[1]])

x_data <- array(dim = c(num_samples, time_steps, num_features))
for (i in 1:num_samples) {
  x_data[i, , ] <- x_padded[[i]]
}

# Reshape y_padded into a 3D array
# Assuming y_padded is structured similarly to x_padded
y_data <- array(dim = c(length(y_padded), max_length, ncol(y_padded[[1]])))
for (i in 1:length(y_padded)) {
  y_data[i, , ] <- y_padded[[i]]
}

beepr::beep()

```

The shape of our 'x' data is 1171 plays, 94 time steps long, by 946 factors wide. 

```{r echo=TRUE}
x_data |> dim()
```

You can see play 1 is 94 time steps long, by 946 factors wide. 

```{r echo=TRUE}
x_data[1,,] |> dim()
```

The shape of our 'y' data is 1171 plays, 94 time steps long, by 11 factors wide - one for each player. 

```{r echo=TRUE}
y_data |> dim()
```

You can see play 1 is 94 time steps long, by 946 factors wide. 

```{r echo=TRUE}
y_data[1,,] |> dim()
```


<!-- ### Spliting and Identifying Data -->

```{r}

# Splitting data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(seq_len(num_samples), size = 0.7 * num_samples)
test_indices <- setdiff(seq_len(num_samples), train_indices)

x_train <- x_data[train_indices, , ]
y_train <- y_data[train_indices, , ]
x_test <- x_data[test_indices, , ]
y_test <- y_data[test_indices, , ]

test_plays <- example_play[-train_indices, ]
test_data <- non_centered_newdata %>%
  semi_join(test_plays, by = c("game_id", "play_id"))

# Apply the function to each element in x_list for tracking
num_players <- 11  # Adjust if necessary
tracking_list <- lapply(x_list, create_tracking_array, max_length = max_length, num_players = num_players)

# Filter out the tracking arrays for the test set

tracking_test <- tracking_list[test_indices]


# if (Sys.info()["user"] == "dusty_turner1") {
#   write_rds(list(x_train = x_train, y_train = y_train, x_test = x_test, y_test = y_test, test_data = test_data, max_length = max_length, time_steps = time_steps, num_samples = num_samples, tracking_test = tracking_test), "04-models/model_data.rds")
# }

```

## Build Model


- **Building the LSTM Model:**
  - `keras_model_sequential()`: Initializes a sequential model.
  - `layer_masking`: Applies masking on the input layer, ignoring zeros for padding.
  - `layer_lstm`: Adds LSTM layers. `return_sequences` is set to `TRUE` for returning sequences.
  - `kernel_regularizer` and `recurrent_regularizer`: Apply L2 regularization to the kernel and recurrent data of the LSTM.
  - `layer_dropout`: Adds dropout layers with a rate of `.75` to prevent overfitting.

- **Compiling the Model:**
  - Compiles the model with:
    - `loss = weighted_binary_crossentropy`: Specifies log loss with weighting to correct balance of 0/1.
    - `optimizer = optimizer_adam(learning_rate = 0.001)`: Uses Adam optimizer with a learning rate of 0.001.
    - `metrics`: Accuracy/Precision/Recall

- **Training the Model:**
  - `model %>% fit`: Trains the model with:
    - Number of epochs (`500`).
    - Batch size (`half of data`).

```{r, echo=TRUE}
run_nn <- function(units_param = 50, rate_param = .5, l2_value_param = .01, epochs_param = 10, 
                   optimizer_param = 'adam', positive_weight_param = 11,
                   layers_param = 3, batch_size_param = 441/1, notes_param = NULL){

  keras::backend()$clear_session()

  positive_weight <- positive_weight_param
  
  raw_tracker <-
    read_csv(here::here("04-models", "model_tracker.csv")) 
    raw_tracker |> 
    filter(epochs == epochs_param, units == units_param, rate == rate_param, 
           l2_value == l2_value_param,
           # activation == activation_param,
           optimizer == optimizer_param, layers == layers_param) %>%
      mutate(model_execution_time = as.character(model_execution_time)) |> 
    print()
    

model <- keras_model_sequential() %>%
  layer_masking(mask_value = 0, input_shape = c(time_steps, num_features)) %>%
  layer_lstm(units = units_param, return_sequences = TRUE, unroll = FALSE,
             kernel_regularizer = regularizer_l2(l2_value_param),
             recurrent_regularizer = regularizer_l2(l2_value_param)) %>%
  layer_dropout(rate = rate_param) %>%
    layer_lstm(units = units_param, return_sequences = TRUE, unroll = FALSE,
             kernel_regularizer = regularizer_l2(l2_value_param),
             recurrent_regularizer = regularizer_l2(l2_value_param)) %>%
  layer_dropout(rate = rate_param) %>%
  time_distributed(layer_dense(units = 11, activation = 'sigmoid'))

model %>% compile(
  loss = weighted_binary_crossentropy,
  optimizer = optimizer_adam(learning_rate = 0.001),
  metrics = list(
    custom_accuracy,       # Assuming this is a predefined metric
    metric_precision(),    # Precision
    metric_recall(),       # Recall
    metric_auc()          # AUC-ROC
  )
)

history <- model %>% fit(
  x = x_train, y = y_train,
  epochs = epochs_param,
  batch_size = batch_size_param,
  validation_data = list(x_test, y_test)
)

return(list(model = model, history = history))  
  
}

ratio <-
newdata %>% 
  count(tackle) %>% 
  reframe(perc = n / sum(n)) %>% 
  slice(1) %>% pull(perc) * 10

out <- run_nn(
  epochs_param = 5,
  units_param = 400,
  rate_param = .75,
  l2_value_param = .001,
  layers_param = 3,
  batch_size_param = 7028/2,
  positive_weight_param = ratio,
  notes_param = "add in play type 2 layers 500 epoch",
  optimizer_param = "adam"
)
```

### Epoch Performance Over Time

```{r}
plot(out$history) +
  geom_line()
```

### Make Predictions

```{r}
y_pred_test <- out$model %>% predict(x_test)

y_pred_binarized <- array(ifelse(y_pred_test > 0.5, 1, 0), dim(y_pred_test))

# Flatten the tracking arrays for the test set
tracking_test_flat <- array_reshape(do.call(cbind, tracking_test), c(dim(y_pred_test)[1] * dim(y_pred_test)[2] * dim(y_pred_test)[3]))

# Flatten your model predictions in a similar manner
predictions_flat <- array_reshape(y_pred_test, c(dim(y_pred_test)[1] * dim(y_pred_test)[2] * dim(y_pred_test)[3]))

# Now, filter out padded predictions using the tracking data
final_predictions <- predictions_flat[tracking_test_flat == 1]

test_joined_with_preds <-
test_data |> 
  arrange(game_id, play_id, frame_id, display_name) |>
  mutate(game_id = as.character(game_id)) |> 
  mutate(play_id = as.character(play_id)) |> 
  mutate(tackle = as.factor(tackle)) |> 
  mutate(final_predictions = as.double(final_predictions)) |> 
  mutate(binary_predictions = as.factor(ifelse(final_predictions> .5, 1, 0))) |> 
  mutate(game_idplay_id = str_c(game_id, play_id))

```


### Tackles over Replacement

To calculate this, I...

The shape of my data for prediction is

```{r, eval=FALSE}
vectors <- NULL
for (i in 1:10) {
  # Create a vector of 10 ones
  vector <- rep(1, 10)
  
  # Replace the ith element with 2
  vector[i] <- 2
  
  # Add the vector to the list
  vectors[[i]] <- vector
}

example_play <- distinct(newdata, game_id, play_id) 

pad_time_series <- function(x, max_length) {
    n_pad <- max_length - nrow(x)
    pad_matrix <- matrix(0, nrow = n_pad, ncol = ncol(x))
    rbind(x, pad_matrix)
}

create_target_matrix <- function(game_id_arg, play_id_arg, df, padded_length) {
    # Filter and arrange data, then transform to wide format
    target_matrix <- df %>%
        filter(game_id == game_id_arg, play_id == play_id_arg) %>%
        arrange(frame_id, display_name) %>%
        select(display_name, tackle) %>%
        distinct() %>%
        pivot_wider(names_from = display_name, values_from = tackle) %>%
        mutate(n_rows = padded_length) %>%
        uncount(n_rows) %>%
        as.matrix()

    # Set column names for clarity
    colnames(target_matrix) <- paste0("Player ", 1:11)
    target_matrix
}

create_tracking_array <- function(x, max_length, num_players) {
    tracking_array <- array(0, dim = c(max_length, num_players))
    if (nrow(x) > 0) {
        tracking_array[1:nrow(x), ] <- 1
    }
    tracking_array
}

these_are_test_set <-
example_play |> 
  mutate(id = row_number()) |> 
  filter(id %in% sort(test_indices)) |> 
  mutate(game_idplay_id = str_c(game_id, play_id))

test_set_data_for_tor <-
newdata |> 
  mutate(game_idplay_id = str_c(game_id, play_id)) |> 
  filter(game_idplay_id %in% these_are_test_set$game_idplay_id)

# double_creater(player_number = 1, vec = vectors[5])

double_creater <- function(player_number, vec){

  print(player_number)
  print(vec)
  
with_double_player <-
test_set_data_for_tor |> 
  group_by(game_idplay_id, frame_id) |>
  filter(row_number() != player_number) |> 
  mutate(id = vec) |> 
  # mutate(id = c(2,1,1,1,1,1,1,1,1,1)) |> 
  ungroup() |> 
  relocate(game_idplay_id, id)  |> 
  uncount(id) |> 
  select(-game_idplay_id)



player_removed <-
test_set_data_for_tor |> 
  group_by(game_idplay_id, frame_id) |> 
  filter(row_number() == player_number) |> 
  ungroup()  |> 
  select(game_idplay_id, display_name) |> 
  distinct()


example_play_1 <-
with_double_player |> 
  distinct(game_id, play_id)

x_list_1 <-
    map2(
      .x = example_play_1$game_id,
      .y = example_play_1$play_id,
      .f = ~ get_play_data(.x, .y, newdata, num_features_per_player_arg = num_features_per_player),
      .progress = TRUE
    )



y_padded_1 <-
    map2(
      .x = example_play_1$game_id,
      .y = example_play_1$play_id,
      .f = ~ create_target_matrix(.x, .y, newdata, padded_length = max_length),
      .progress = TRUE
    )

x_padded_1 <- lapply(x_list_1, pad_time_series, max_length = max_length)

x_data_1 <- array(dim = c(length(x_padded_1), time_steps, num_features))
for (i in 1:length(x_padded_1)) {
  x_data_1[i, , ] <- x_padded_1[[i]]
}

y_data_1 <- array(dim = c(length(y_padded_1), max_length, ncol(y_padded_1[[1]])))
for (i in 1:length(y_padded_1)) {
  y_data_1[i, , ] <- y_padded_1[[i]]
}

tracking_list_1 <- lapply(x_list_1, create_tracking_array, max_length = max_length, num_players = 11)
tracking_test_1 <- tracking_list_1

y_pred_test_1 <- out$model %>% predict(x_data_1)

y_pred_binarized_1 <- array(ifelse(y_pred_test_1 > 0.5, 1, 0), dim(y_pred_test_1))

# Calculate accuracy
# accuracy_1 <- sum(y_pred_binarized_1 == y_data_1) / length(y_data_1)

# Print accuracy
# print(paste("Accuracy:", accuracy_1))

# Flatten the tracking arrays for the test set
tracking_test_flat_1 <- array_reshape(do.call(cbind, tracking_test_1), c(dim(y_pred_test_1)[1] * dim(y_pred_test_1)[2] * dim(y_pred_test_1)[3]))

# Flatten your model predictions in a similar manner
predictions_flat_1 <- array_reshape(y_pred_test_1, c(dim(y_pred_test_1)[1] * dim(y_pred_test_1)[2] * dim(y_pred_test_1)[3]))

# Now, filter out padded predictions using the tracking data
final_predictions_1 <- predictions_flat_1[tracking_test_flat_1 == 1]

test_joined_with_preds_1 <-
with_double_player |> 
  arrange(game_id, play_id, frame_id, display_name) |>
  mutate(game_id = as.character(game_id)) |> 
  mutate(play_id = as.character(play_id)) |> 
  mutate(tackle = as.factor(tackle)) |> 
  mutate(final_predictions_1 = as.double(final_predictions_1)) |> 
  mutate(binary_predictions_1 = as.factor(ifelse(final_predictions_1> .5, 1, 0))) |> 
  mutate(game_idplay_id = str_c(game_id, play_id))

test_joined_with_preds_1 |> 
  select(game_idplay_id, display_name, frame_id, tackle, final_predictions_1) |> 
  left_join(test_joined_with_preds |> select(game_idplay_id, display_name, frame_id, final_predictions)) |> 
  group_by(game_idplay_id, frame_id, display_name) |> 
  filter(row_number() != 2) |> 
  ungroup() |> 
  mutate(delta_probability_added = final_predictions - final_predictions_1) |> 
  group_by(game_idplay_id) |> 
  summarise(increase_in_tackle_prob = sum(delta_probability_added)) |> 
  ungroup() |> 
  left_join(player_removed) %>% 
  mutate(player_number = player_number)

}

library(furrr)
plan(multisession)
options(future.globals.maxSize = 10000000000)
tictoc::tic()
player_out_results <-
map2_dfr(.x = sort(rep(1:10, 10)), .y = rep(vectors,10), .f = ~double_creater(player_number = .x, vec = .y), .id = "vector_id", .progress = TRUE)
tictoc::toc()

# player_out_results %>% write_parquet(here::here("04-models","player_out_results_small_demo.parquet"))
```


```{r}

player_out_results <- read_parquet(here::here("04-models","player_out_results_small_demo.parquet"))

player_probability_increase_by_play <-
player_out_results %>% filter(!is.na(increase_in_tackle_prob)) %>% 
  group_by(game_idplay_id, display_name) %>% 
  summarise(total_increase_in_tackle_prob = mean(increase_in_tackle_prob, na.rm = TRUE)) 

average_probability_increase <-
player_probability_increase_by_play %>% 
  group_by(display_name) %>% 
  summarise(average_play_increase = mean(total_increase_in_tackle_prob), n = n())

average_probability_increase %>% 
  left_join(week_1 %>% select(display_name, position, club) %>% distinct()) %>% 
  # filter(n > 19) %>% 
  group_by(club) %>% 
  filter(average_play_increase == min(average_play_increase)) %>% arrange(-average_play_increase)

# week_1 |> distinct(club) |> 
  # print(n = Inf)

library(kableExtra)

average_probability_increase %>% 
  left_join(week_1 %>% select(display_name, position, club) %>% distinct()) %>% 
  distinct(display_name, average_play_increase, n, position, .keep_all = TRUE) |> 
  # filter(n > 19) %>% 
  arrange(-average_play_increase) |> 
  mutate(average_play_increase =  round(average_play_increase, 1)) |> 
  left_join(team_colors) |> 
  slice(1:5) |> 
  select(-n) |> 
  rename(Player = 1, ATPA = 2, Position = 3, Team = 4)  |> 
  select(-Color) |> 
  kableExtra::kable()


average_probability_increase %>% 
  left_join(week_1 %>% select(display_name, position, club) %>% distinct()) %>% 
  distinct(display_name, average_play_increase, n, position, .keep_all = TRUE) |>
  # filter(n > 19) %>% 
  arrange(average_play_increase) |> 
  mutate(average_play_increase =  round(average_play_increase, 1)) |> 
  left_join(team_colors) |> 
  slice(1:5) |> 
  select(-n) |> 
  rename(Player = 1, ATPA = 2, Position = 3, Team = 4)  |> 
  select(-Color) |> 
  kableExtra::kable()


atpa <-
average_probability_increase %>%
  # filter(n >= 20) %>%
  ggplot(aes(y = average_play_increase, x = fct_reorder(display_name, -average_play_increase), fill = average_play_increase)) +
  geom_col() +
  scale_fill_viridis_c() +
  # scale_fill_gradient(low = "firebrick", high = "forestgreen") +
  theme_minimal(15) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), legend.position = "none", panel.grid.major = element_blank()) +
  labs(x = "", y = "Tackle Probability Added")

# ggsave(filename = "05-presentation-files/atpa.svg", plot = atpa, width = 10, height = 8)
atpa
```




```{r}
test_joined_with_preds |> 
  select(game_idplay_id, final_predictions,binary_predictions, tackle, display_name, frame_id, position, club) |> 
  mutate(tackle = as.numeric(as.character(tackle))) |> 
  mutate(tackles_over_expected_frame = tackle - final_predictions) |> 
  group_by(display_name, game_idplay_id, position, club) |> 
  summarise(tackles_over_expected_play = mean(tackles_over_expected_frame)) |> 
  group_by(display_name, position, club) |> 
  summarise(tackles_over_expected_per_play = mean(tackles_over_expected_play), plays = n()) |> 
  ungroup() |> 
  filter(plays >=20) |> 
  arrange(-tackles_over_expected_per_play) |> 
  select(-plays) |> 
  slice(1:5) |> 
  rename(Player = 1, Position = 2, Team = 3, TOE = 4) |> 
  mutate(TOE = round(TOE,3)) |> 
  kableExtra::kable()

test_joined_with_preds |> 
  select(game_idplay_id, final_predictions,binary_predictions, tackle, display_name, frame_id, position, club) |> 
  mutate(tackle = as.numeric(as.character(tackle))) |> 
  mutate(tackles_over_expected_frame = tackle - final_predictions) |> 
  group_by(display_name, game_idplay_id, position, club) |> 
  summarise(tackles_over_expected_play = mean(tackles_over_expected_frame)) |> 
  group_by(display_name, position, club) |> 
  summarise(tackles_over_expected_per_play = mean(tackles_over_expected_play), plays = n()) |> 
  ungroup() |> 
  filter(plays >=20) |> 
  arrange(tackles_over_expected_per_play) |> 
  select(-plays) |> 
  slice(1:5) |> 
  rename(Player = 1, Position = 2, Team = 3, TOE = 4) |> 
  mutate(TOE = round(TOE,3)) |> 
  kableExtra::kable() 


toe_plot <-
test_joined_with_preds |> 
  select(game_idplay_id, final_predictions,binary_predictions, tackle, display_name, frame_id, position, club) |> 
  distinct(game_idplay_id, frame_id, display_name, .keep_all = TRUE) |> 
  mutate(tackle = as.numeric(as.character(tackle))) |> 
  mutate(tackles_over_expected_frame = tackle - final_predictions) |> 
  group_by(display_name, game_idplay_id, position, club) |> 
  summarise(tackles_over_expected_play = mean(tackles_over_expected_frame)) |> 
  group_by(display_name, position, club) |> 
  summarise(tackles_over_expected_per_play = mean(tackles_over_expected_play), plays = n()) |> 
  ungroup() |> 
  filter(plays >= 20) |> distinct(display_name, .keep_all = TRUE)  |> 
  ggplot(aes(y = tackles_over_expected_per_play, x = fct_reorder(display_name, -tackles_over_expected_per_play), fill = tackles_over_expected_per_play)) +
  geom_col() +
  scale_fill_viridis_c() +
  # scale_fill_gradient(low = "firebrick", high = "forestgreen") +
  theme_minimal(15) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), legend.position = "none", panel.grid.major = element_blank()) +
  labs(x = "", y = "Tackles Over Expected") +
  ylim(-.5,.25)

```




## Other

```{r}
non_centered_newdata_for_log <-
deff |> 
  mutate(across(.cols = all_of(should_be_factors), ~as.factor(.))) |> 
  mutate(tackle = as.numeric(as.character(tackle))) |> 
  mutate(across(.cols = all_of(should_be_factors), .fns = ~if_else(is.na(.), "unknown", .))) |> 
  mutate(across(.cols = all_of(should_be_factors), ~as.factor(.))) |> 
  # as.data.table() |> one_hot() |> 
  # as_tibble() |> 
  mutate(across(.cols = where(is.character), .fns = ~as.factor(.))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.nan(.), NA, .))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.infinite(.), NA, .))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.na(.), mean(., na.rm = T), .))) |> 
  mutate(game_id = as.numeric(as.character(game_id))) |> 
  mutate(play_id = as.numeric(as.character(play_id))) |> 
  group_by(game_id, play_id, display_name, frame_id) |> ## because one play had two of these per player/frame for some reason
  mutate(x_from_los = mean(x_from_los)) |> 
  ungroup() |> 
  distinct(.keep_all = TRUE) |> 
  select(game_id,play_id, display_name, frame_id, all_of(continuous_factors), all_of(contains(discrete_factors)), tackle) |> 
  arrange(game_id, play_id, frame_id, display_name) |> 
  mutate(across(.cols = all_of(continuous_factors),  .fns = ~ (. - mean(.)) / sd(.))) |> 
  mutate(game_idplay_id = str_c(game_id,play_id)) |> 
  relocate(game_idplay_id)

library(rsample)
set.seed(123)
data_split <- rsample::group_initial_split(non_centered_newdata_for_log, prop = 0.75, group = game_idplay_id) 

# Extract the training and test sets
train_data <- training(data_split)
test_data <- testing(data_split)


mod <- glm(formula = tackle ~ ., data = select(train_data, -game_id, -play_id, -display_name, -frame_id))

predi

```

