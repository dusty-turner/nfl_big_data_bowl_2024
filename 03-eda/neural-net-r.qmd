---
title: "Neural-net"
author: "Dusty Turner"
format: html
engines:
  R: true
  python: true
cache: true
warning: false
message: false
---

## Testing

```{r}
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
library(data.table)
library(gganimate)
library(furrr)
plan(multisession)

source(here::here("03-eda","ggtheme_field.R"))
if(digest::sha1(read_lines(here::here("03-eda", "data_cleaning.R"))) != read_lines(here::here("02-clean-data", "cleaninghash.txt"))){
source(here::here("03-eda", "data_cleaning.R"))
} else {
  defensive_model_building_data <- read_rds(here::here("02-clean-data", "data_cleaning_working.RDS"))
  week_1 <- read_rds(here::here("02-clean-data", "week_1.RDS"))
}
```

```{r}
deff <-
defensive_model_building_data %>% 
  filter(is.na(pass_result)) |>
  filter(frame_id >= 5) |> 
  filter(frames_from_tackle <=0) |> 

  # filter(frames_from_tackle >=-5) %>% 

  ## end finds frames from tackle
  mutate(position = as.character(position)) %>%
  mutate(position = replace_na(position, "unknown")) %>%
  mutate(position = factor(position)) |> 
  select(c(x,y,distance_to_ball, distance_to_ball_next, x_going, y_going, s, a, o, dir, x_ball, y_ball, x_ball_next, y_ball_next, s_ball, o_ball, dir_ball, angle_to_ball,
           position, offense_formation, quarter, down, rank,
           defenders_in_the_box, ball_in_fan3, ball_in_fan2, ball_in_fan1, pass_probability, yards_to_go, x_from_los, height, weight, tackle, frames_from_tackle, game_id, play_id, nfl_id, frame_id, display_name, game_idplay_id)) 

library(mltools)
library(data.table)

should_be_factors <- c("ball_in_fan3", "ball_in_fan2", "ball_in_fan1", "position", "offense_formation", "quarter", "down", "rank", "defenders_in_the_box")

newdata <-
  deff |> 
  mutate(across(.cols = all_of(should_be_factors), ~as.factor(.))) |> 
  mutate(tackle = as.numeric(as.character(tackle))) |> 
  mutate(across(.cols = all_of(should_be_factors), .fns = ~if_else(is.na(.), "unknown", .))) |> 
  mutate(across(.cols = all_of(should_be_factors), ~as.factor(.))) |> 
  as.data.table() |> one_hot() |> 
  as_tibble() |> 
  mutate(across(.cols = where(is.character), .fns = ~as.factor(.))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.nan(.), NA, .))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.infinite(.), NA, .))) |> 
  mutate(across(.cols = where(is.numeric), .fns = ~if_else(is.na(.), mean(., na.rm = T), .))) |> 
  mutate(game_id = as.numeric(as.character(game_id))) |> 
  mutate(play_id = as.numeric(as.character(play_id))) |> 
  select(game_id,play_id, display_name, frame_id, x, y, x_ball, y_ball, s, a, o, distance_to_ball, tackle) |> 
  distinct(.keep_all = TRUE) |> 
  arrange(game_id, play_id, frame_id, display_name)

```

### Shape up Data

```{r}
# Function to extract play data for a given game and play id
get_play_data <- function(game_id_arg, play_id_arg, df, num_features_per_player) {
    # Select and arrange relevant data
    play_data <- df %>%
        filter(game_id == game_id_arg, play_id == play_id_arg) %>%
        arrange(frame_id, display_name)

    # Determine the number of unique frames and players
    num_frames <- length(unique(play_data$frame_id))
    num_players <- length(unique(play_data$display_name))

    # Initialize a matrix to store play data
    play_matrix <- matrix(nrow = num_frames, ncol = num_players * num_features_per_player)

    # Populate the matrix with data for each frame
    for (i in seq_len(num_frames)) {
        frame_data <- play_data %>%
            filter(frame_id == unique(play_data$frame_id)[i]) %>%
            select(x, y, x_ball, y_ball, s, a, o, distance_to_ball)
        play_matrix[i, ] <- as.numeric(t(frame_data))
    }
    play_matrix
}

# Extract unique game and play combinations from the dataset
example_play <- distinct(newdata, game_id, play_id)

# Generate a list of matrices for each play
x_list <- future_map2(
  .x = example_play$game_id, 
  .y = example_play$play_id, 
  .f = ~get_play_data(.x, .y, newdata, num_features_per_player = 8), 
  .progress = TRUE
)

# Determine the maximum sequence length and pad all sequences
max_length <- max(sapply(x_list, nrow))

pad_time_series <- function(x, max_length) {
    n_pad <- max_length - nrow(x)
    pad_matrix <- matrix(0, nrow = n_pad, ncol = ncol(x))
    rbind(x, pad_matrix)
}

x_padded <- lapply(x_list, pad_time_series, max_length = max_length)

# Function to create target matrices for each play
create_target_matrix <- function(game_id_arg, play_id_arg, df, padded_length) {
    # Filter and arrange data, then transform to wide format
    target_matrix <- df %>%
        filter(game_id == game_id_arg, play_id == play_id_arg) %>%
        arrange(frame_id, display_name) %>%
        select(display_name, tackle) %>%
        distinct() %>%
        pivot_wider(names_from = display_name, values_from = tackle) %>%
        mutate(n_rows = padded_length) %>%
        uncount(n_rows) %>%
        as.matrix()

    # Set column names for clarity
    colnames(target_matrix) <- paste0("Player ", 1:11)
    target_matrix
}

# Generate target matrices for each play
y_padded <- future_map2(
    .x = example_play$game_id, 
    .y = example_play$play_id, 
    .f = ~create_target_matrix(.x, .y, newdata, padded_length = max_length),
    .progress = TRUE
)

# Function to create a tracking array indicating the presence of data per player
create_tracking_array <- function(x, max_length, num_players) {
    tracking_array <- array(0, dim = c(max_length, num_players))
    if (nrow(x) > 0) {
        tracking_array[1:nrow(x), ] <- 1
    }
    tracking_array
}

# Generate tracking arrays for each play
tracking_list <- lapply(x_list, create_tracking_array, max_length = max_length, num_players = 11)

# Reshape x_padded into a 3D array
num_samples <- length(x_padded)
time_steps <- max_length  # Assuming max_length is already defined
num_features <- ncol(x_padded[[1]])

x_data <- array(dim = c(num_samples, time_steps, num_features))
for (i in 1:num_samples) {
  x_data[i, , ] <- x_padded[[i]]
}

# Reshape y_padded into a 3D array
# Assuming y_padded is structured similarly to x_padded
y_data <- array(dim = c(length(y_padded), max_length, ncol(y_padded[[1]])))
for (i in 1:length(y_padded)) {
  y_data[i, , ] <- y_padded[[i]]
}

```

### Spliting and Identifying Data

```{r}

# Splitting data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(seq_len(num_samples), size = 0.7 * num_samples)
test_indices <- setdiff(seq_len(num_samples), train_indices)

x_train <- x_data[train_indices, , ]
y_train <- y_data[train_indices, , ]
x_test <- x_data[test_indices, , ]
y_test <- y_data[test_indices, , ]

test_plays <- example_play[-train_indices, ]
test_data <- newdata %>%
  semi_join(test_plays, by = c("game_id", "play_id"))

# Apply the function to each element in x_list for tracking
num_players <- 11  # Adjust if necessary
tracking_list <- lapply(x_list, create_tracking_array, max_length = max_length, num_players = num_players)

# Filter out the tracking arrays for the test set
tracking_test <- tracking_list[test_indices]
```

### Model Stuff

```{r}
# Define the LSTM model architecture
model <- keras_model_sequential() %>%
  layer_masking(mask_value = 0, input_shape = c(max_length, num_features)) %>%
  bidirectional(layer_lstm(units = 50, return_sequences = TRUE)) %>%
  layer_dropout(rate = 0.4) %>%
  bidirectional(layer_lstm(units = 50, return_sequences = TRUE)) %>%
  layer_dropout(rate = 0.4) %>%
  bidirectional(layer_lstm(units = 50, return_sequences = TRUE)) %>%
  layer_dropout(rate = 0.4) %>%
  # bidirectional(layer_lstm(units = 50, return_sequences = TRUE)) %>%
  # layer_dropout(rate = 0.2) %>%
  # bidirectional(layer_lstm(units = 50, return_sequences = TRUE)) %>%
  # layer_dropout(rate = 0.2) %>%
  # bidirectional(layer_lstm(units = 50, return_sequences = TRUE)) %>%
  # layer_dropout(rate = 0.2) %>%
  time_distributed(layer_dense(units = 11, activation = 'sigmoid'))  # Adjust the unit count based on output shape

# Compile the model
model %>% compile(
  loss = 'binary_crossentropy',
  optimizer = 'adam',
  metrics = 'accuracy'
)

# Callbacks for early stopping and saving the best model
early_stopping <- callback_early_stopping(
  monitor = "val_loss",
  patience = 10,
  restore_best_weights = TRUE
)

model_checkpoint <- callback_model_checkpoint(
  filepath = "best_model.h5",
  monitor = "val_loss",
  save_best_only = TRUE
)

callbacks_list <- list(early_stopping, model_checkpoint)

x_train |> dim()

# Train the model
history <- model %>% fit(
  x = x_train, y = y_train,
  epochs = 2000,
  batch_size = 441/1,  # this is how many sequences go at once
  # callbacks = callbacks_list  # Include callbacks here
  validation_data = list(x_test, y_test),
)

# View the training history
plot(history)
# history$metrics |> as_tibble() |> print(n = Inf)
```

### Accuracy


```{r}
# Predict on test data
y_pred_test <- model %>% predict(x_test)

# Binarize predictions (since we used a sigmoid activation, the output is a probability)
y_pred_binarized <- array(ifelse(y_pred_test > 0.5, 1, 0), dim(y_pred_test))

# Calculate accuracy
accuracy <- sum(y_pred_binarized == y_test) / length(y_test)

# Print accuracy
print(paste("Accuracy:", accuracy))

# Flatten the tracking arrays for the test set
tracking_test_flat <- array_reshape(do.call(cbind, tracking_test), c(dim(y_pred_test)[1] * dim(y_pred_test)[2] * dim(y_pred_test)[3]))

# Flatten your model predictions in a similar manner
predictions_flat <- array_reshape(y_pred_test, c(dim(y_pred_test)[1] * dim(y_pred_test)[2] * dim(y_pred_test)[3]))

# Now, filter out padded predictions using the tracking data
final_predictions <- predictions_flat[tracking_test_flat == 1]


test_joined_with_preds <-
test_data |> 
  arrange(game_id, play_id, frame_id, display_name) |>
  mutate(game_id = as.character(game_id)) |> 
  mutate(play_id = as.character(play_id)) |> 
  mutate(tackle = as.factor(tackle)) |> 
  mutate(final_predictions = as.double(final_predictions)) |> 
  mutate(binary_predictions = as.factor(ifelse(final_predictions> .5, 1, 0))) 

test_joined_with_preds |> 
  count(binary_predictions)

test_joined_with_preds |> 
  yardstick::accuracy(truth = tackle, estimate = binary_predictions)




test_joined_with_preds |> 
  group_by(game_id, play_id) |>
  filter(cur_group_id() == 1) |> 
  arrange(display_name) |> 
  print(n = Inf)
```


```{r}

library(pROC)

# Creating the ROC object
roc_result<- roc(response = test_joined_with_preds$tackle, predictor = test_joined_with_preds$final_predictions)

# Calculating the AUC
auc_value <- auc(roc_result)

# Plotting the ROC curve
ggplot(data = data.frame(fpr = 1 - roc_result$specificities, tpr = roc_result$sensitivities), aes(x = fpr, y = tpr)) +
  geom_line() +
  geom_abline(linetype = "dashed") +
  labs(x = "False Positive Rate", y = "True Positive Rate", title = "ROC Curve") +
  annotate("text", x = 0.6, y = 0.4, label = paste("AUC =", round(auc_value, 2)))
```


## Animations

```{r}
library(gganimate)

# Assuming week_1 is your data frame
animated_plot <-
  week_1 %>% 
  left_join(test_joined_with_preds %>% select(game_id, play_id, display_name, frame_id, final_predictions), by = c("game_id", "play_id", "display_name", "frame_id")) %>% 
  filter(!is.na(final_predictions)) %>% 
  group_by(game_id, play_id) %>% 
  filter(cur_group_id() == 1) |> 
  ungroup()  |> 
  select(frame_id, final_predictions, jersey_number) |> 
  ggplot(aes(x = frame_id, y = final_predictions)) + 
  geom_line() +
  geom_point(show.legend = FALSE, size = 3) + 
  facet_wrap(~jersey_number) +
  transition_reveal(frame_id)

anm1 <- animate(animated_plot, width = 800, height = 600, nframes = 100)

animated_plot2 <-
week_1 |> 
  filter(play_id %in% test_joined_with_preds$play_id) |> 
  filter(game_id %in% test_joined_with_preds$game_id) |> 
  left_join(
    test_joined_with_preds |> select(game_id, play_id, display_name, frame_id, final_predictions) |> 
      mutate(final_predictions = ifelse(is.na(final_predictions), 0, final_predictions))
    ) |> 
  group_by(game_id, play_id) |> 
  filter(cur_group_id() == 1) |>
  filter(frame_id >=5) |> 
  filter(frame_id <= max(frame_id)-4) |> 
  mutate(final_predictions = ifelse(club == defensive_team & is.na(final_predictions), 0, final_predictions)) |> 
  ungroup()  |> 
  mutate(color = final_predictions) |> 
  mutate(jersey_number = ifelse(defensive_team == club, jersey_number, "")) |> 
  select(display_name, distance_to_ball, x, y, color, absolute_yardline_number, ball_carrier, play_id, time, play_description, is_football, club, jersey_number, final_predictions, defensive_team, frame_id) %>%
  # filter(club == defensive_team) |> select(final_predictions, frame_id, display_name) |> print(n = Inf) |> pull(final_predictions) |> hist()
{
  ggplot(data = ., aes(x = x, y = y, color = color)) +
  geom_vline(aes(xintercept = absolute_yardline_number), color = "blue") +
  geom_point(aes(shape = is_football), size = 3, show.legend = FALSE) +
  geom_text(aes(label = jersey_number), color = "black", nudge_y = -1) +
  scale_color_gradient(low = "grey", high = "black", na.value = "dodgerblue") +
  transition_time(time) + ease_aes("linear") +
  labs(y = "", x = "Yards To Endzone", title = str_wrap(.$play_description[1], width = 80)) +
  theme_field
}

anm2 <- animate(animated_plot2, width = 800, height = 600, nframes = 100)

nn_briar <- 
  test_joined_with_preds |> 
  select(game_id, play_id, display_name,tackle, final_predictions) |> 
  filter(!is.na(final_predictions)) |> 
  mutate(tackle  = as.integer(as.character(tackle))) |> 
  group_by(game_id, play_id, display_name) |> 
  reframe(expected_prob_of_tackle = mean(final_predictions), tackle = mean(tackle)) |> 
  mutate(tackles_over_expected_play = ifelse(tackle == 1, 1-expected_prob_of_tackle, -expected_prob_of_tackle)) |> 
  group_by(display_name) |> 
  reframe(tackles_over_expected = sum(tackles_over_expected_play)) |> 
  arrange(-tackles_over_expected)


```

