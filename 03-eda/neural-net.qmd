---
title: "Neural-net"
author: "Dusty Turner"
format: html
engines:
  R: true
  python: true
cache: true
warning: false
message: false
---

## Testing

```{r}
library(tidyverse)
library(tidymodels)
library(reticulate)
source(here::here("03-eda", "data_cleaning.R"))
```

```{r}

deff <-
defensive_model_building_data %>% 
  filter(is.na(pass_result)) |>
  filter(frame_id >= 5) |> 
  ## finds frames from tackle
  group_by(game_id,play_id, nfl_id) |> 
  # filter(cur_group_id() == 1) |> 
  mutate(row_with_tackle = mean(ifelse(event == "tackle", cur_group_rows(), NA ), na.rm = TRUE)) |> 
  mutate(frames_from_tackle = cur_group_rows() - row_with_tackle) |> 
  ungroup() |> 
  filter(frames_from_tackle <=0) |> 
  select(-row_with_tackle) |> 
  ## end finds frames from tackle
  mutate(position = as.character(position)) %>%
  mutate(position = replace_na(position, "unknown")) %>%
  mutate(position = factor(position)) |> 
  mutate(offense_formation = if_else(is.na(offense_formation), "unk", offense_formation)) |> 
  mutate(alignment_cluster = if_else(is.na(alignment_cluster), "unk", alignment_cluster)) |> 
  select(c(x,y,distance_to_ball, distance_to_ball_next, x_going, y_going, s, a, o, dir, x_ball, y_ball, x_ball_next, y_ball_next, s_ball, o_ball, dir_ball, angle_to_ball,
           position, offense_formation, quarter, down, rank,
           defenders_in_the_box, ball_in_fan, pass_probability, yards_to_go, x_from_los, height, weight, tackle, frames_from_tackle, game_id, play_id, nfl_id, frame_id)) 



```





```{python}
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GroupShuffleSplit
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import classification_report
from tensorflow.keras.layers import LSTM

# Load and preprocess data
# Replace 'r.deff' with your actual DataFrame name
data = r.deff
data.replace([np.inf, -np.inf], np.nan, inplace=True)  # Handle infinite values

nan_counts = data.isna().sum()
print(nan_counts)

# Define feature categories
numerical_features = ['x', 'y', 'distance_to_ball', 'distance_to_ball_next', 'x_going', 'y_going', 's', 'a', 'o', 'dir', 'x_ball', 'y_ball', 'x_ball_next', 'y_ball_next', 'pass_probability', 'yards_to_go', 'x_from_los', 'rank', 'height', 'weight', 's_ball', 'angle_to_ball']
categorical_features = ['ball_in_fan', 'position', 'offense_formation', 'quarter', 'down']

# For numerical columns
# data['numerical_column'] = data['numerical_column'].fillna(data['numerical_column'].mean())

# For categorical columns
# data['categorical_column'] = data['categorical_column'].fillna('Unknown')


# Set up preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline([
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numerical_features),
        ('cat', Pipeline([
            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_features)
    ]
)

# Split data based on 'game_id'
group_column = 'game_id'
target_column = 'tackle'
additional_columns = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'frames_from_tackle']  # Specify additional columns to keep

gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=0)
for train_idx, test_idx in gss.split(data, data[target_column], data[group_column]):
    train_data = data.iloc[train_idx]
    test_data = data.iloc[test_idx]

# Store additional columns and then drop them from the feature set
additional_columns_train = train_data[additional_columns].copy()
additional_columns_test = test_data[additional_columns].copy()

X_train = train_data.drop([target_column] + additional_columns, axis=1)
y_train = train_data[target_column].astype(int)
X_test = test_data.drop([target_column] + additional_columns, axis=1)
y_test = test_data[target_column].astype(int)

# Build the model
def build_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=[input_shape], kernel_regularizer=l2(0.0005)),
        Dropout(0.1),
        Dense(64, activation='relu', kernel_regularizer=l2(0.0005)),
        Dropout(0.1),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model
  
# def build_lstm_model(input_shape):
#     model = Sequential([
#         LSTM(64, return_sequences=True, input_shape=[None, input_shape], kernel_regularizer=l2(0.0005)),
#         Dropout(0.1),
#         LSTM(64, return_sequences=False, kernel_regularizer=l2(0.0005)),
#         Dropout(0.1),
#         Dense(1, activation='sigmoid')
#     ])
#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
#     return model

# Preprocess the data
X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

# Convert the target variable to numpy array if it's a pandas Series
y_train_np = y_train.values if isinstance(y_train, pd.Series) else y_train
y_test_np = y_test.values if isinstance(y_test, pd.Series) else y_test

# Now build the model with the correct input shape
model = build_model(X_train_transformed.shape[1])
# model = build_lstm_model(X_train_transformed.shape[1])

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, verbose=1),
    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)
]

# Train the model with callbacks
history = model.fit(X_train_transformed, y_train_np, epochs=7, validation_split=0.2, callbacks=callbacks)

# After making predictions
predictions = model.predict(X_test_transformed)
predicted_classes = (predictions > 0.5).astype(int)

# Evaluate the model
evaluation = model.evaluate(X_test_transformed, y_test_np)
print("Test loss:", evaluation[0])
print("Test accuracy:", evaluation[1])

# Now, you can use additional_columns_test in R for your analysis along with predictions


```

```{r}

test_set_with_predictions <-
  as_tibble(py$X_test) %>% 
  mutate(tackle = as.factor(py$y_test), 
         pred_class = as.factor(py$predicted_classes),
         pred = py$predictions[,1],
         game_id = py$additional_columns_test$game_id,
         play_id = py$additional_columns_test$play_id,
         nfl_id = py$additional_columns_test$nfl_id,
         frame_id = py$additional_columns_test$frame_id,
         frames_from_tackle = py$additional_columns_test$frames_from_tackle)  |>  filter(frames_from_tackle >= -40) |> 
  relocate(game_id, play_id, pred, frames_from_tackle, tackle)  

test_set_with_predictions |> 
  group_by(frames_from_tackle) |>
  yardstick::accuracy(truth = tackle, pred_class) |> 
  ggplot(aes(x = frames_from_tackle, y = .estimate)) +
  geom_line()

animated_plot <-
week_1 |> 
  left_join(test_set_with_predictions |> select(game_id, play_id, nfl_id, frame_id, pred)) |> 
  filter(!is.na(pred)) |> 
  group_by(game_id, play_id) |> filter(cur_group_id() == 1) |> ungroup() |> 
  ggplot(aes(x = frame_id, y = pred)) + 
  geom_line() +
  geom_point(show.legend = FALSE, size = 3) + # Add a point for each line
  facet_wrap(~jersey_number) +
  transition_reveal(frame_id) # Animate the points along the line

anm1 <- animate(animated_plot, width = 800, height = 600, nframes = 100)

animated_plot2 <-
week_1 |> 
  filter(play_id %in% test_set_with_predictions$play_id) |> 
  filter(game_id %in% test_set_with_predictions$game_id) |> 
  left_join(
    test_set_with_predictions |> select(game_id, play_id, nfl_id, frame_id, pred) |> 
      mutate(pred = ifelse(is.na(pred), 0, pred))
    ) |> 
  group_by(game_id, play_id) |> 
  filter(cur_group_id() == 1) |>
  mutate(pred = ifelse(club == defensive_team & is.na(pred), 0, pred)) |> 
  ungroup()  |> 
  mutate(color = pred) |> 
  mutate(jersey_number = ifelse(defensive_team == club, jersey_number, "")) |> 
  select(distance_to_ball, x, y, color, absolute_yardline_number, ball_carrier, play_id, time, play_description, is_football, club, jersey_number, defensive_team) %>%
{
  ggplot(data = ., aes(x = x, y = y, color = color)) +
  geom_vline(aes(xintercept = absolute_yardline_number), color = "blue") +
  geom_point(aes(shape = is_football), size = 3, show.legend = FALSE) +
  geom_text(aes(label = jersey_number), color = "black", nudge_y = -1) +
  scale_color_gradient(low = "grey", high = "black", na.value = "dodgerblue") +
  transition_time(time) + ease_aes("linear") +
  labs(y = "", x = "Yards To Endzone", title = str_wrap(.$play_description[1], width = 80)) +
  theme_field
}

anm2 <- animate(animated_plot2, width = 800, height = 600, nframes = 100)





```

```{r}
preds_in_r <-
as_tibble(py$X_test) |> 
  mutate(tackle = as.factor(py$y_test)) |> 
  mutate(pred = as.factor(py$predicted_classes))



```


## This works on work computer

```{r}
# library(reticulate)
# Sys.setenv(RETICULATE_PYTHON = "C:/Users/Dusty_Turner1/AppData/Local/Programs/Python/Python311/python.exe")
# options(reticulate.use_condaenv = FALSE)
# use_python("C:/Users/Dusty_Turner1/AppData/Local/Programs/Python/Python311/python.exe", required = TRUE)
# "C:/Users/Dusty_Turner1/AppData/Local/Programs/Python/Python311/python.exe" -m pip install pandas

```

```{python}
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load and preprocess data
# Assuming r.deff is your DataFrame loaded previously
data = r.deff  
data.replace([np.inf, -np.inf], np.nan, inplace=True)  # Handle infinite values

# Define feature categories
numerical_features = ['x', 'y', 'distance_to_ball', 'distance_to_ball_next', 'x_going', 'y_going', 's', 'a', 'o', 'dir', 'x_ball', 'y_ball',  'x_ball_next', 'y_ball_next', 'pass_probability', 'yards_to_go', 'x_from_los', 'rank', 'height', 'weight', 's_ball', 'o_ball', 'dir_ball', 'angle_to_ball']
categorical_features = ['ball_in_fan', 'position', 'offense_formation', 'quarter', 'down']

# Set up preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline([
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numerical_features),
        ('cat', Pipeline([
            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_features)
    ]
)

# Split data
X = data.drop('tackle', axis=1)
y = data['tackle'].astype(int)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Build the model
def build_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=[input_shape]),
        Dense(64, activation='relu'),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

model = build_model(X_train_transformed.shape[1])

# Create the pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', model)
])

# Train the pipeline
pipeline = Pipeline([('preprocessor', preprocessor), ('model', build_model(preprocessor.fit_transform(X_train).shape[1]))])
history = pipeline.fit(X_train, y_train, model__epochs=7, model__validation_split=0.2)

# Evaluate model
test_loss, test_accuracy = pipeline.named_steps['model'].evaluate(pipeline.named_steps['preprocessor'].transform(X_test), y_test, verbose=2)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

```

## Make Predictions

```{python}
# Transform the test data using the preprocessor in the pipeline
X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)

# Use the model to make predictions on the transformed test data
predictions = pipeline.named_steps['model'].predict(X_test_transformed)

# Since predictions will be in the form of probabilities (due to the sigmoid activation), 
# you might want to convert these to a binary form (0 or 1) based on a threshold (usually 0.5)
predicted_classes = (predictions > 0.5).astype(int)

# predicted_classes now holds the vector of predictions (0 or 1) for the test set

```

```{r}
library(reticulate)
py$X_test |> as_tibble() |> 
  mutate(tackle = as.factor(py$y_test), prediction = py$predictions[,1], class = as.factor(py$predicted_classes[,1])) |> 
  select(tackle, prediction, class) |> 
  yardstick::accuracy(truth = tackle, estimate = class)
```

